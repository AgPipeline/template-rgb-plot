{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template RGB Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing modules for the Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/jacobvanderleeuw/miniconda/lib/python3.8/site-packages (1.20.2)\n",
      "Requirement already satisfied: pandas in /Users/jacobvanderleeuw/miniconda/lib/python3.8/site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/jacobvanderleeuw/miniconda/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/jacobvanderleeuw/miniconda/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/jacobvanderleeuw/miniconda/lib/python3.8/site-packages (from pandas) (1.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jacobvanderleeuw/miniconda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: pillow in /Users/jacobvanderleeuw/miniconda/lib/python3.8/site-packages (8.2.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "import textwrap\n",
    "import urllib.request as urllib\n",
    "import zipfile\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tkinter.filedialog import askdirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure that you are in the correct directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"README.md\"):\n",
    "    os.chdir(\"./{{cookiecutter._project_name}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-level Docstring. Change this to reflect your algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"My nifty plot-level RGB algorithm\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports into the python file. Please add any additional import statements that will be needed for your algorithm below"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the version number of your algorithm. Consider using [Semantic Versioning](https://semver.org/)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "VERSION = '1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide information on the creator and contributors of this algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ALGORITHM_AUTHOR = 'Unknown'\n",
    "ALGORITHM_AUTHOR_EMAIL = 'author@example.com'\n",
    "ALGORITHM_CONTRIBUTORS = [\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name and describe your algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ALGORITHM_NAME = 'algorithm'\n",
    "ALGORITHM_DESCRIPTION = 'add description here'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide citation information for algorithm publication. This includes the citation author, the citation title, and the citation year"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CITATION_AUTHOR = 'add citation author'\n",
    "CITATION_TITLE = 'add citation title'\n",
    "CITATION_YEAR = '2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include the name(s) of the variable(s) used in the algorithm, separated by commas. Note that variable names cannot have comma's in them: use a different separator instead. Also, all white space is kept intact; don't add any extra whitespace since it may cause name comparisons to fail"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "VARIABLE_NAMES = 'size of image channels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include the units and labels of the variables, matching the order of VARIABLE_NAMES, also separated by commas. VARIABLE_LABELS is an optional field and can be left empty."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "VARIABLE_UNITS = 'pixels'\n",
    "VARIABLE_LABELS = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional override for the generation of a BETYdb compatible csv file. Set to False to suppress the creation of a compatible file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "WRITE_BETYDB_CSV = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional override for the generation of a TERRA REF Geostreams compatible csv file. Set the variable to False to suppress the creation of a compatible file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "WRITE_GEOSTREAMS_CSV = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the url below to get images from a different source. This assumes that the image files are contained within a .zip file. The code below will add the sample_plot_images chosen to the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://de.cyverse.org/dl/d/4108BB75-AAA3-48E1-BBD4-E10B06CADF54/sample_plot_images.zip\"\n",
    "\n",
    "if os.path.isdir(\"sample_plot_images\"):\n",
    "    shutil.rmtree(\"sample_plot_images\")\n",
    "os.mkdir(\"sample_plot_images\")\n",
    "if not os.path.isfile(\"sample_plot_images.zip\"):\n",
    "    urllib.urlretrieve(url, \"sample_plot_images.zip\")\n",
    "zipfile.ZipFile(\"sample_plot_images.zip\", 'r').extractall(\"sample_plot_images\")\n",
    "os.remove(\"sample_plot_images.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your calculate() function"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def calculate(pxarray: np.ndarray):\n",
    "    \"\"\"Calculates one or more values from plot-level RGB data\n",
    "    Arguments:\n",
    "        pxarray: Array of RGB data for a single plot\n",
    "    Return:\n",
    "        Returns one or more calculated values\n",
    "    \"\"\"\n",
    "    # ALGORITHM: replace the following lines with your algorithm\n",
    "    channel_size = pxarray[:, :, 1].size*5\n",
    "    # RETURN: replace the following return with your calculated values.\n",
    "    # Be sure to order them as defined in VARIABLE_NAMES above\n",
    "    return channel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update algorithm_rgb.py with your changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_algorithm_rgb_file():\n",
    "    cells = json.load(open(\"../template-rgb-plot.ipynb\"))[\"cells\"]\n",
    "    with open(\"algorithm_rgb.py\", \"w\") as outfile:\n",
    "        for key in cells:\n",
    "            toWrite = \"\"\n",
    "            if key[\"cell_type\"] == \"markdown\":\n",
    "                for entry in key[\"source\"]:\n",
    "                    if entry[0:4] == \"####\":\n",
    "                        entry = re.sub('####', '', entry).lstrip()\n",
    "                        toWrite = toWrite + entry\n",
    "                        toWrite = format_string(toWrite)\n",
    "                        outfile.write(\"\\n\\n\" + str(toWrite) + \"\\n\")\n",
    "            elif key[\"cell_type\"] == \"raw\":\n",
    "                for entry in key[\"source\"]:\n",
    "                    toWrite = toWrite + entry\n",
    "                outfile.write(str(toWrite))\n",
    "        outfile.write(\"\\n\")\n",
    "                \n",
    "def format_string(toWrite):\n",
    "    returnStr = \"\"\n",
    "    lines = textwrap.wrap(toWrite, width=115, break_long_words=False)\n",
    "    for line in range(len(lines)):\n",
    "        if line != len(lines)-1:\n",
    "            returnStr = returnStr + \"# \" + lines[line] + \"\\n\"\n",
    "        else: \n",
    "            returnStr = returnStr + \"# \" + lines[line]\n",
    "    return returnStr\n",
    "\n",
    "write_algorithm_rgb_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the calculate() function on the sample plot images located in the sample_plot_images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000\n",
      "35000\n",
      "35000\n",
      "35000\n",
      "35000\n",
      "35000\n"
     ]
    }
   ],
   "source": [
    "import algorithm_rgb\n",
    "for filename in os.listdir(\"sample_plot_images\"):\n",
    "    img = Image.open(\"sample_plot_images/\" + filename)\n",
    "    img_arr = np.array(img)\n",
    "    print(algorithm_rgb.calculate(img_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Generate your Dockerfile by running the generate.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd0 = \"python generate.py\"\n",
    "os.system(cmd0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If there are leftover files from previous runs, delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = [\"result.json\", \"rgb_plot.csv\", \"rgb_plot_betydb.csv\", \"rgb_plot_geo.csv\"]\n",
    "for file in filelist:\n",
    "    if os.path.isfile(file):\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now build the dockerfile (Currently this will have a default project name and project version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = \"docker build -t \" + algorithm_rgb.ALGORITHM_NAME + \":\" + algorithm_rgb.VERSION + \" .\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next run the dockerfile for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = 'docker run --rm --mount \"src=`pwd`,target=/mnt,type=bind\" ' + algorithm_rgb.ALGORITHM_NAME + \":\" + algorithm_rgb.VERSION + ' --working_space \"/mnt\"'\n",
    "for filename in os.listdir(\"sample_plot_images\"):\n",
    "    cmd += ' \"/mnt/sample_plot_images/' + filename + '\"'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure that the correct files are generated and contain appropriate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = [\"result.json\", \"rgb_plot.csv\", \"rgb_plot_betydb.csv\", \"rgb_plot_geo.csv\"]\n",
    "saveDir = \"outputs_\" + str(datetime.now()).replace(\" \", \"\").replace(\":\", \".\")\n",
    "Path.mkdir(Path.cwd() / saveDir)\n",
    "saveDir = Path.cwd() / saveDir\n",
    "\n",
    "for filename in filelist:\n",
    "    assert os.path.isfile(filename)\n",
    "    if (file == \"result.json\"):\n",
    "        result = json.load(open(file))[algorithm_rgb.ALGORITHM_NAME]\n",
    "        assert result['version'] == algorithm_rgb.VERSION\n",
    "        assert result['traits'] == algorithm_rgb.VARIABLE_NAMES\n",
    "        assert result['units'] == algorithm_rgb.VARIABLE_UNITS\n",
    "        assert result['labels'] == algorithm_rgb.VARIABLE_LABELS\n",
    "        assert result['files_processed'] == str(len(os.listdir(\"sample_plot_images\")))\n",
    "        assert result['lines_written'] == str(len(os.listdir(\"sample_plot_images\")))\n",
    "        if (algorithm_rgb.WRITE_GEOSTREAMS_CSV == True):\n",
    "            assert result['wrote_geostreams'] == \"Yes\"\n",
    "        else:\n",
    "            assert result['wrote_geostreams'] == \"No\"\n",
    "        if (algorithm_rgb.WRITE_BETYDB_CSV == True):\n",
    "            assert result['wrote_betydb'] == \"Yes\"\n",
    "        else: \n",
    "            assert result['wrote_betydb'] == \"No\"\n",
    "    os.system(\"mv \" + filename + \" \" + str(saveDir / Path(filename).name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the output files. They will be displayed in the following order: \n",
    "## 1.) result.json\n",
    "## 2.) rgb_plot.csv\n",
    "## 3.) rgb_plot_betydb.csv\n",
    "## 4.) rgb_plot_geo.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'file': [{'path': '/mnt/rgb_plot.csv', 'key': 'csv'}, {'path': '/mnt/rgb_plot_geo.csv', 'key': 'csv'}, {'path': '/mnt/rgb_plot_betydb.csv', 'key': 'csv'}], 'algorithm': {'version': '1.0', 'traits': 'size of image channels', 'units': 'pixels', 'labels': '', 'files_processed': '6', 'lines_written': '6', 'wrote_geostreams': 'Yes', 'wrote_betydb': 'Yes'}}\n"
     ]
    }
   ],
   "source": [
    "print(json.load(open((saveDir / \"result.json\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   species                site   timestamp        lat         lon  \\\n",
      "0  Unknown  sample_plot_images  2021-04-28  33.075194 -111.974953   \n",
      "1  Unknown  sample_plot_images  2021-04-28  33.075949 -111.974888   \n",
      "2  Unknown  sample_plot_images  2021-04-28  33.074727 -111.975043   \n",
      "3  Unknown  sample_plot_images  2021-04-28  33.074547 -111.975027   \n",
      "4  Unknown  sample_plot_images  2021-04-28  33.075697 -111.974937   \n",
      "5  Unknown  sample_plot_images  2021-04-28  33.074691 -111.974888   \n",
      "\n",
      "       citation_author  citation_year      citation_title  \\\n",
      "0  add citation author           2020  add citation title   \n",
      "1  add citation author           2020  add citation title   \n",
      "2  add citation author           2020  add citation title   \n",
      "3  add citation author           2020  add citation title   \n",
      "4  add citation author           2020  add citation title   \n",
      "5  add citation author           2020  add citation title   \n",
      "\n",
      "   size of image channels (pixels)  \n",
      "0                          35000.0  \n",
      "1                          35000.0  \n",
      "2                          35000.0  \n",
      "3                          35000.0  \n",
      "4                          35000.0  \n",
      "5                          35000.0  \n"
     ]
    }
   ],
   "source": [
    "rgb_plot = pd.read_csv((saveDir / \"rgb_plot.csv\"))\n",
    "print(rgb_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        local_datetime  access_level  species                site  \\\n",
      "0  2021-04-28T17:23:34             2  Unknown  sample_plot_images   \n",
      "1  2021-04-28T17:23:34             2  Unknown  sample_plot_images   \n",
      "2  2021-04-28T17:23:34             2  Unknown  sample_plot_images   \n",
      "3  2021-04-28T17:23:34             2  Unknown  sample_plot_images   \n",
      "4  2021-04-28T17:23:34             2  Unknown  sample_plot_images   \n",
      "5  2021-04-28T17:23:34             2  Unknown  sample_plot_images   \n",
      "\n",
      "       citation_author  citation_year      citation_title   method  \\\n",
      "0  add citation author           2020  add citation title  Unknown   \n",
      "1  add citation author           2020  add citation title  Unknown   \n",
      "2  add citation author           2020  add citation title  Unknown   \n",
      "3  add citation author           2020  add citation title  Unknown   \n",
      "4  add citation author           2020  add citation title  Unknown   \n",
      "5  add citation author           2020  add citation title  Unknown   \n",
      "\n",
      "   size of image channels  \n",
      "0                 35000.0  \n",
      "1                 35000.0  \n",
      "2                 35000.0  \n",
      "3                 35000.0  \n",
      "4                 35000.0  \n",
      "5                 35000.0  \n"
     ]
    }
   ],
   "source": [
    "rgb_plot_betydb = pd.read_csv((saveDir / \"rgb_plot_betydb.csv\"))\n",
    "print(rgb_plot_betydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 site                   trait        lat         lon  \\\n",
      "0  sample_plot_images  size of image channels  33.075194 -111.974953   \n",
      "1  sample_plot_images  size of image channels  33.075949 -111.974888   \n",
      "2  sample_plot_images  size of image channels  33.074727 -111.975043   \n",
      "3  sample_plot_images  size of image channels  33.074547 -111.975027   \n",
      "4  sample_plot_images  size of image channels  33.075697 -111.974937   \n",
      "5  sample_plot_images  size of image channels  33.074691 -111.974888   \n",
      "\n",
      "               dp_time                                   source    value  \\\n",
      "0  2021-04-28T17:23:34   /mnt/sample_plot_images/rgb_17_7_W.tif  35000.0   \n",
      "1  2021-04-28T17:23:34  /mnt/sample_plot_images/rgb_40_11_W.tif  35000.0   \n",
      "2  2021-04-28T17:23:34    /mnt/sample_plot_images/rgb_6_1_E.tif  35000.0   \n",
      "3  2021-04-28T17:23:34    /mnt/sample_plot_images/rgb_1_2_E.tif  35000.0   \n",
      "4  2021-04-28T17:23:34   /mnt/sample_plot_images/rgb_33_8_W.tif  35000.0   \n",
      "5  2021-04-28T17:23:34   /mnt/sample_plot_images/rgb_5_11_W.tif  35000.0   \n",
      "\n",
      "    timestamp  \n",
      "0  2021-04-28  \n",
      "1  2021-04-28  \n",
      "2  2021-04-28  \n",
      "3  2021-04-28  \n",
      "4  2021-04-28  \n",
      "5  2021-04-28  \n"
     ]
    }
   ],
   "source": [
    "rgb_plot_geo = pd.read_csv((saveDir / \"rgb_plot_geo.csv\"))\n",
    "print(rgb_plot_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can now generate your repo using the cookiecutter utility, documented at https://github.com/cookiecutter/cookiecutter/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_project_name': 'Name your Project', '_url': 'https://github.com/AgPipeline/template-rgb-plot', '_version': 'Replace this text with the algorithm version', '_author(s)': ['Replace this text with the algorithm author(s), separated by commas'], '_author_email(s)': ['Replace this text with the algorithm author email(s), separated by commas'], '_contributors': ['Replace this text with the algorithm contributors, separated by commas'], '_algorithm_name': 'Replace this text with the name of the algorithm', '_algorithm_description': 'Replace this text with a description of the algorithm', '_citation_author': 'Replace this text with the citation author for publication', '_citation_title': 'Replace this text with the citation title for publication', '_citation_year': 'Replace this text with the citation year for publication', '_variable_names': [\"Replace this text with your variable names. Note that variable names cannot have comma's in them. Additionally, don't add any whitespace since it may cause name comparisons to fail.\"], '_variable_units': ['Replace this text with your variable unit(s) and comma-separate values'], '_variable_labels': ['Variable labels matching the order of variable names, also comma-separated'], '_methods': ['add algorithm_rgb.py methods here', '_get_variables_header_fields', 'print_usage', 'check_arguments', 'check_configuration', 'run_test', 'process_files'], '_checkLinks': True}\n"
     ]
    }
   ],
   "source": [
    "template = open(Path.cwd().parent / \"template_cookiecutter.json\",\"r\") \n",
    "contents = json.load(template)\n",
    "template.close()\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please update the fields below to reflect what is needed in your repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents[\"_project_name\"] = \"NameyourProject\"\n",
    "\n",
    "contents[\"_url\"] = \"https://github.com/AgPipeline/template-rgb-plot\"\n",
    "\n",
    "contents[\"_version\"] = \"Replace this text with the algorithm version\"\n",
    "\n",
    "contents[\"_author(s)\"] = [\"Replace this text with the algorithm author(s), separated by commas\"]\n",
    "\n",
    "contents[\"_author_email(s)\"] = [\"Replace this text with the algorithm author email(s), separated by commas\"]\n",
    "\n",
    "contents[\"_contributors\"] = [\"Replace this text with the algorithm contributors, separated by commas\"]\n",
    "\n",
    "contents[\"_algorithm_name\"] = \"Replace this text with the name of the algorithm\"\n",
    "\n",
    "contents[\"_algorithm_description\"] = \"Replace this text with a description of the algorithm\"\n",
    "\n",
    "contents[\"_citation_author\"] = \"Replace this text with the citation author for publication\"\n",
    "\n",
    "contents[\"_citation_title\"] = \"Replace this text with the citation title for publication\"\n",
    "\n",
    "contents[\"_citation_year\"] = \"Replace this text with the citation year for publication\"\n",
    "\n",
    "contents[\"_variable_names\"] = [\"Replace this text with your variable names. Note that variable names cannot have comma's in them. Additionally, don't add any whitespace since it may cause name comparisons to fail.\"]\n",
    "\n",
    "contents[\"_variable_units\"] = [\"Replace this text with your variable unit(s) and comma-separate values\"]\n",
    "\n",
    "contents[\"_variable_labels\"] = [\"Variable labels matching the order of variable names, also comma-separated\"]\n",
    "\n",
    "contents[\"_methods\"] = [\"add algorithm_rgb.py methods here\", \"_get_variables_header_fields\",\n",
    "    \"print_usage\", \"check_arguments\", \"check_configuration\", \"run_test\", \"process_files\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookiecutter_file = open((Path.cwd().parent / \"cookiecutter.json\"),\"w\")\n",
    "json.dump(contents,cookiecutter_file)\n",
    "cookiecutter_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please specify the directory at which you would like for your repository to be located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_to_use = str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now you can generate your repository using cookiecutter. Make sure that you have cookiecutter installed. Installations can be found at: https://command-not-found.com/cookiecutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.isfile(\"README.md\"):\n",
    "    os.chdir(\"..\")\n",
    "os.system(\"cookiecutter -f \" + str(Path.cwd()) + \" -o \" + directory_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
